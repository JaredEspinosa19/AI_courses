{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./dataset_ES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 error que el mujer cometer en el primero cita</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increíble mascarilla borrar el mancha como si ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 ejercicio CON silla fácil práctico rápido de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huevo Hervido así él preparar este Excelente R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el tipo más rallado en este mundo que tal tú p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  label\n",
       "0  10 error que el mujer cometer en el primero cita       1\n",
       "1  increíble mascarilla borrar el mancha como si ...      1\n",
       "2  5 ejercicio CON silla fácil práctico rápido de...      1\n",
       "3  Huevo Hervido así él preparar este Excelente R...      1\n",
       "4  el tipo más rallado en este mundo que tal tú p...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, Dropout\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df1['tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df1['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_y, test_y = train_test_split(tweets, label,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\preprocessing\\text.py:246: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31852 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "# get the raw text data\n",
    "texts_train = train_text.astype(str)\n",
    "texts_test = test_text.astype(str)\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\n",
    "tokenizer.fit_on_texts(texts_train)\n",
    "sequences = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (24000, 150)\n",
      "Shape of data test tensor: (6000, 150)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "# pad sequences with 0s\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of data test tensor:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (24000, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_y\n",
    "y_test = test_y\n",
    "\n",
    "y_train = to_categorical(np.asarray(y_train))\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "N_CLASSES = 2\n",
    "\n",
    "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "average = GlobalAveragePooling1D()(embedded_sequences)\n",
    "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
    "\n",
    "model = Model(sequence_input, predictions)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\choc-\\OneDrive\\Documents\\Python\\CIC\\cic_redes\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "169/169 [==============================] - 3s 15ms/step - loss: 0.6891 - acc: 0.5701 - val_loss: 0.6831 - val_acc: 0.5858\n",
      "Epoch 2/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.6708 - acc: 0.6297 - val_loss: 0.6565 - val_acc: 0.6450\n",
      "Epoch 3/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.6435 - acc: 0.6487 - val_loss: 0.6334 - val_acc: 0.6521\n",
      "Epoch 4/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.6169 - acc: 0.6743 - val_loss: 0.6161 - val_acc: 0.6754\n",
      "Epoch 5/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5903 - acc: 0.6994 - val_loss: 0.5994 - val_acc: 0.6654\n",
      "Epoch 6/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5656 - acc: 0.7207 - val_loss: 0.5834 - val_acc: 0.6929\n",
      "Epoch 7/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5406 - acc: 0.7478 - val_loss: 0.5715 - val_acc: 0.7021\n",
      "Epoch 8/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5191 - acc: 0.7608 - val_loss: 0.5628 - val_acc: 0.7021\n",
      "Epoch 9/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4982 - acc: 0.7758 - val_loss: 0.5543 - val_acc: 0.7033\n",
      "Epoch 10/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4795 - acc: 0.7876 - val_loss: 0.5482 - val_acc: 0.7079\n",
      "Epoch 11/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4628 - acc: 0.7987 - val_loss: 0.5435 - val_acc: 0.7075\n",
      "Epoch 12/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4477 - acc: 0.8046 - val_loss: 0.5438 - val_acc: 0.7121\n",
      "Epoch 13/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4319 - acc: 0.8154 - val_loss: 0.5378 - val_acc: 0.7129\n",
      "Epoch 14/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4172 - acc: 0.8229 - val_loss: 0.5369 - val_acc: 0.7100\n",
      "Epoch 15/40\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4039 - acc: 0.8318 - val_loss: 0.5423 - val_acc: 0.7092\n",
      "Epoch 16/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3917 - acc: 0.8400 - val_loss: 0.5374 - val_acc: 0.7125\n",
      "Epoch 17/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3794 - acc: 0.8446 - val_loss: 0.5384 - val_acc: 0.7129\n",
      "Epoch 18/40\n",
      "169/169 [==============================] - 2s 15ms/step - loss: 0.3683 - acc: 0.8493 - val_loss: 0.5423 - val_acc: 0.7125\n",
      "Epoch 19/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3571 - acc: 0.8555 - val_loss: 0.5459 - val_acc: 0.7092\n",
      "Epoch 20/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3481 - acc: 0.8596 - val_loss: 0.5454 - val_acc: 0.7150\n",
      "Epoch 21/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3382 - acc: 0.8624 - val_loss: 0.5509 - val_acc: 0.7108\n",
      "Epoch 22/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3290 - acc: 0.8680 - val_loss: 0.5528 - val_acc: 0.7117\n",
      "Epoch 23/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3206 - acc: 0.8703 - val_loss: 0.5584 - val_acc: 0.7117\n",
      "Epoch 24/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3119 - acc: 0.8764 - val_loss: 0.5657 - val_acc: 0.7075\n",
      "Epoch 25/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3039 - acc: 0.8796 - val_loss: 0.5735 - val_acc: 0.7029\n",
      "Epoch 26/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2964 - acc: 0.8825 - val_loss: 0.5895 - val_acc: 0.6954\n",
      "Epoch 27/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2899 - acc: 0.8855 - val_loss: 0.5778 - val_acc: 0.7092\n",
      "Epoch 28/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2828 - acc: 0.8886 - val_loss: 0.5846 - val_acc: 0.7058\n",
      "Epoch 29/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2757 - acc: 0.8908 - val_loss: 0.5945 - val_acc: 0.7029\n",
      "Epoch 30/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2688 - acc: 0.8950 - val_loss: 0.6046 - val_acc: 0.7025\n",
      "Epoch 31/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2631 - acc: 0.8968 - val_loss: 0.6301 - val_acc: 0.6946\n",
      "Epoch 32/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2583 - acc: 0.8980 - val_loss: 0.6115 - val_acc: 0.7042\n",
      "Epoch 33/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2512 - acc: 0.9016 - val_loss: 0.6271 - val_acc: 0.7000\n",
      "Epoch 34/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2466 - acc: 0.9035 - val_loss: 0.6280 - val_acc: 0.7013\n",
      "Epoch 35/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2409 - acc: 0.9061 - val_loss: 0.6348 - val_acc: 0.7021\n",
      "Epoch 36/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2367 - acc: 0.9087 - val_loss: 0.6432 - val_acc: 0.7008\n",
      "Epoch 37/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2321 - acc: 0.9107 - val_loss: 0.6541 - val_acc: 0.7025\n",
      "Epoch 38/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2267 - acc: 0.9106 - val_loss: 0.6609 - val_acc: 0.6979\n",
      "Epoch 39/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2214 - acc: 0.9148 - val_loss: 0.6741 - val_acc: 0.6988\n",
      "Epoch 40/40\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.2207 - acc: 0.9142 - val_loss: 0.6786 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a929190f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1,\n",
    "          epochs=40, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step\n",
      "test auc: 0.7566424396123672\n"
     ]
    }
   ],
   "source": [
    "output_test = model.predict(x_test)\n",
    "print(\"test auc:\", roc_auc_score(y_test,output_test[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(output_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./Test-ES-nolabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebas1 = df2['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruebas1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebas = tokenizer.texts_to_sequences(pruebas1)\n",
    "pruebas_finales = pad_sequences(pruebas, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "output_test1 = model.predict(pruebas_finales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finales = np.argmax(output_test1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_finales = finales.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['labels_predichos'] = lista_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Test-ES-labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cic_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
